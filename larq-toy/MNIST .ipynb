{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import larq as lq\n",
    "import larq_compute_engine as lce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# Normalize pixel values to be between -1 and 1\n",
    "train_images, test_images = train_images / 127.5 - 1, test_images / 127.5 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All quantized layers except the first will use the same options\n",
    "kwargs = dict(input_quantizer=\"ste_sign\",\n",
    "              kernel_quantizer=\"ste_sign\",\n",
    "              kernel_constraint=\"weight_clip\")\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# In the first layer we only quantize the weights and not the input\n",
    "model.add(lq.layers.QuantConv2D(32, (3, 3),\n",
    "                                kernel_quantizer=\"ste_sign\",\n",
    "                                kernel_constraint=\"weight_clip\",\n",
    "                                use_bias=False,\n",
    "                                input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False, **kwargs))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False, **kwargs))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(lq.layers.QuantDense(64, use_bias=False, **kwargs))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(tf.keras.layers.Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+sequential stats------------------------------------------------------------------------------------------+\n",
      "| Layer                  Input prec.           Outputs  # 1-bit  # 32-bit  Memory  1-bit MACs  32-bit MACs |\n",
      "|                              (bit)                        x 1       x 1    (kB)                          |\n",
      "+----------------------------------------------------------------------------------------------------------+\n",
      "| quant_conv2d                     -  (-1, 26, 26, 32)      288         0    0.04           0       194688 |\n",
      "| max_pooling2d                    -  (-1, 13, 13, 32)        0         0       0           0            0 |\n",
      "| batch_normalization              -  (-1, 13, 13, 32)        0        64    0.25           0            0 |\n",
      "| quant_conv2d_1                   1  (-1, 11, 11, 64)    18432         0    2.25     2230272            0 |\n",
      "| max_pooling2d_1                  -    (-1, 5, 5, 64)        0         0       0           0            0 |\n",
      "| batch_normalization_1            -    (-1, 5, 5, 64)        0       128    0.50           0            0 |\n",
      "| quant_conv2d_2                   1    (-1, 3, 3, 64)    36864         0    4.50      331776            0 |\n",
      "| batch_normalization_2            -    (-1, 3, 3, 64)        0       128    0.50           0            0 |\n",
      "| flatten                          -         (-1, 576)        0         0       0           0            0 |\n",
      "| quant_dense                      1          (-1, 64)    36864         0    4.50       36864            0 |\n",
      "| batch_normalization_3            -          (-1, 64)        0       128    0.50           0            0 |\n",
      "| quant_dense_1                    1          (-1, 10)      640         0    0.08         640            0 |\n",
      "| batch_normalization_4            -          (-1, 10)        0        20    0.08           0            0 |\n",
      "| activation                       -          (-1, 10)        0         0       0           ?            ? |\n",
      "+----------------------------------------------------------------------------------------------------------+\n",
      "| Total                                                   93088       468   13.19     2599552       194688 |\n",
      "+----------------------------------------------------------------------------------------------------------+\n",
      "+sequential summary----------------------------+\n",
      "| Total params                      93.6 k     |\n",
      "| Trainable params                  93.1 k     |\n",
      "| Non-trainable params              468        |\n",
      "| Model size                        13.19 KiB  |\n",
      "| Model size (8-bit FP weights)     11.82 KiB  |\n",
      "| Float-32 Equivalent               365.45 KiB |\n",
      "| Compression Ratio of Memory       0.04       |\n",
      "| Number of MACs                    2.79 M     |\n",
      "| Ratio of MACs that are binarized  0.9303     |\n",
      "+----------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "lq.models.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "938/938 [==============================] - 29s 31ms/step - loss: 0.6455 - accuracy: 0.9096\n",
      "Epoch 2/6\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.4736 - accuracy: 0.9622\n",
      "Epoch 3/6\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.4481 - accuracy: 0.9690\n",
      "Epoch 4/6\n",
      "938/938 [==============================] - 28s 29ms/step - loss: 0.4356 - accuracy: 0.9731\n",
      "Epoch 5/6\n",
      "938/938 [==============================] - 28s 29ms/step - loss: 0.4291 - accuracy: 0.9755\n",
      "Epoch 6/6\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.4248 - accuracy: 0.9770\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4460 - accuracy: 0.9699\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, batch_size=64, epochs=6)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 96.99 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy {test_acc * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /var/folders/3x/f8xkz0ld28s8ty74_v94rnp40000gn/T/tmpmfqquklo/assets\n"
     ]
    }
   ],
   "source": [
    "# Convert our Keras model to a TFLite flatbuffer file\n",
    "with open(\"./tflite-models/mnist.tflite\", \"wb\") as flatbuffer_file:\n",
    "    flatbuffer_bytes = lce.convert_keras_model(model)\n",
    "    flatbuffer_file.write(flatbuffer_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat experiments but with neural networks that have all continuous precision layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# In the first layer we only quantize the weights and not the input\n",
    "model.add(lq.layers.QuantConv2D(32, (3, 3),\n",
    "                                use_bias=False,\n",
    "                                input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "\n",
    "model.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(lq.layers.QuantDense(64, use_bias=False))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(lq.layers.QuantDense(10, use_bias=False))\n",
    "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
    "model.add(tf.keras.layers.Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+sequential_3 stats--------------------------------------------------------------------+\n",
      "| Layer                   Input prec.           Outputs  # 32-bit  Memory  32-bit MACs |\n",
      "|                               (bit)                         x 1    (kB)              |\n",
      "+--------------------------------------------------------------------------------------+\n",
      "| quant_conv2d_9                    -  (-1, 26, 26, 32)       288    1.12       194688 |\n",
      "| max_pooling2d_6                   -  (-1, 13, 13, 32)         0       0            0 |\n",
      "| batch_normalization_14            -  (-1, 13, 13, 32)        64    0.25            0 |\n",
      "| quant_conv2d_10                   -  (-1, 11, 11, 64)     18432   72.00      2230272 |\n",
      "| max_pooling2d_7                   -    (-1, 5, 5, 64)         0       0            0 |\n",
      "| batch_normalization_15            -    (-1, 5, 5, 64)       128    0.50            0 |\n",
      "| quant_conv2d_11                   -    (-1, 3, 3, 64)     36864  144.00       331776 |\n",
      "| batch_normalization_16            -    (-1, 3, 3, 64)       128    0.50            0 |\n",
      "| flatten_3                         -         (-1, 576)         0       0            0 |\n",
      "| quant_dense_5                     -          (-1, 64)     36864  144.00        36864 |\n",
      "| batch_normalization_17            -          (-1, 64)       128    0.50            0 |\n",
      "| quant_dense_6                     -          (-1, 10)       640    2.50          640 |\n",
      "| batch_normalization_18            -          (-1, 10)        20    0.08            0 |\n",
      "| activation_2                      -          (-1, 10)         0       0            ? |\n",
      "+--------------------------------------------------------------------------------------+\n",
      "| Total                                                     93556  365.45      2794240 |\n",
      "+--------------------------------------------------------------------------------------+\n",
      "+sequential_3 summary-----------------------+\n",
      "| Total params                   93.6 k     |\n",
      "| Trainable params               93.1 k     |\n",
      "| Non-trainable params           468        |\n",
      "| Model size                     365.45 KiB |\n",
      "| Model size (8-bit FP weights)  91.36 KiB  |\n",
      "| Float-32 Equivalent            365.45 KiB |\n",
      "| Compression Ratio of Memory    1.00       |\n",
      "| Number of MACs                 2.79 M     |\n",
      "+-------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "lq.models.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "938/938 [==============================] - 26s 27ms/step - loss: 0.5609 - accuracy: 0.9551\n",
      "Epoch 2/6\n",
      "938/938 [==============================] - 27s 28ms/step - loss: 0.4871 - accuracy: 0.9743\n",
      "Epoch 3/6\n",
      "938/938 [==============================] - 26s 28ms/step - loss: 0.4706 - accuracy: 0.9792\n",
      "Epoch 4/6\n",
      "478/938 [==============>...............] - ETA: 13s - loss: 0.4633 - accuracy: 0.9808"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, batch_size=64, epochs=6)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test accuracy {test_acc * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our Keras model to a TFLite flatbuffer file\n",
    "with open(\"./tflite-models/mnist_full_precision.tflite\", \"wb\") as flatbuffer_file:\n",
    "    flatbuffer_bytes = lce.convert_keras_model(model)\n",
    "    flatbuffer_file.write(flatbuffer_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
